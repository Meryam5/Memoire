{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70620a85",
   "metadata": {},
   "source": [
    "### Historique données spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e268dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages nécessaires\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94a2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin d'accès\n",
    "data = r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\HPFC\\historique_spot\"\n",
    "Output = r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\P50\\Injection\\test-models\\Consommation\\Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4dd058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Meryam GHASSIR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Meryam GHASSIR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Meryam GHASSIR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Meryam GHASSIR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Meryam GHASSIR\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table spot_2005 créée - Shape: (254, 25)\n",
      "Table spot_2006 créée - Shape: (365, 25)\n",
      "Table spot_2007 créée - Shape: (365, 25)\n",
      "Table spot_2008 créée - Shape: (366, 25)\n",
      "Table spot_2009 créée - Shape: (365, 25)\n",
      "Erreur lors de la lecture du fichier pour l'année 2010: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2011: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2012: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2013: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2014: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2015: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2016: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2017: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Erreur lors de la lecture du fichier pour l'année 2018: '$A$' is not a valid column name. Column names are from A to ZZZ\n",
      "Table spot_2019 créée - Shape: (5367, 25)\n",
      "Table spot_2020 créée - Shape: (366, 25)\n",
      "Table spot_2021 créée - Shape: (365, 25)\n",
      "Table spot_2022 créée - Shape: (365, 25)\n",
      "Table spot_2023 créée - Shape: (365, 25)\n",
      "Table spot_2024 créée - Shape: (366, 25)\n",
      "Traitement terminé - bien vérifier les fichiers créés et les fichiers manquants\n"
     ]
    }
   ],
   "source": [
    "# Lecture et Récupération des données utilisées (date + prix spot)\n",
    "# On supprime les colonnes dont on n'a pas besoin en plus\n",
    "for year in range(2005, 2025):\n",
    "    try:\n",
    "        file_path = os.path.join(data, f\"auction_spot_france_{year}.xlsx\")\n",
    "        if os.path.exists(file_path):\n",
    "            spot_year = pd.read_excel(file_path, header=1, sheet_name=\"Prices\")\n",
    "        else:\n",
    "            file_path = os.path.join(data, f\"auction_spot_prices_france_{year}.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                spot_year = pd.read_csv(file_path, header=1, sep=',')\n",
    "            else:\n",
    "                print(f\"Le fichier pour l'année {year} n'existe pas.\")\n",
    "                continue\n",
    "    \n",
    "        # On garde les colonnes de A à Z (date + prix spot)\n",
    "        spot_year = spot_year.iloc[:, 0:26]\n",
    "        spot_year = spot_year.drop(columns=['Hour 3B', 'Hour3B'], errors='ignore')\n",
    "        spot_year = spot_year.rename(columns={'Hour3A': 'Hour3', 'Hour 3A': 'Hour 3'})\n",
    "    \n",
    "        # Créer la variable dynamiquement\n",
    "        globals()[f'spot_{year}'] = spot_year\n",
    "    \n",
    "        print(f\"Table spot_{year} créée - Shape: {spot_year.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier pour l'année {year}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"Traitement terminé - bien vérifier les fichiers créés et les fichiers manquants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e919a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table spot_2012 créée - Shape: (2811, 25)\n",
      "Table spot_2013 créée - Shape: (3176, 25)\n",
      "Table spot_2014 créée - Shape: (3541, 25)\n",
      "Table spot_2015 créée - Shape: (3906, 25)\n",
      "Table spot_2016 créée - Shape: (4272, 25)\n",
      "Table spot_2017 créée - Shape: (4637, 25)\n",
      "Table spot_2018 créée - Shape: (5002, 25)\n"
     ]
    }
   ],
   "source": [
    "# Traitement des fichiers non lus (2010 à 2018)\n",
    "for year in range(2012, 2019):\n",
    "    try:\n",
    "        file_path = os.path.join(data, f\"auction_spot_prices_france_{year}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            spot_year = pd.read_csv(file_path, header=1, sep=',')\n",
    "        else:\n",
    "            print(f\"Le fichier pour l'année {year} n'existe pas.\")\n",
    "            continue\n",
    "    \n",
    "        # On garde les colonnes de A à Z (date + prix spot)\n",
    "        spot_year = spot_year.iloc[:, 0:26]\n",
    "        spot_year = spot_year.drop(columns=['Hour 3B', 'Hour3B'], errors='ignore')\n",
    "        spot_year = spot_year.rename(columns={'Hour3A': 'Hour3', 'Hour 3A': 'Hour 3'})\n",
    "    \n",
    "        # Créer la variable dynamiquement\n",
    "        globals()[f'spot_{year}'] = spot_year\n",
    "    \n",
    "        print(f\"Table spot_{year} créée - Shape: {spot_year.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier pour l'année {year}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893c4d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table spot_2005_2019 créée - Shape: (5367, 47)\n",
      "     Delivery day  Hour 1  Hour 2  Hour 3A  Hour 3B  Hour 4  Hour 5  Hour 6  \\\n",
      "5362   26/04/2005  33.664  32.002   30.328      NaN  27.296  27.006  33.108   \n",
      "5363   25/04/2005  29.003  28.324   27.047      NaN  23.186  18.976  32.009   \n",
      "5364   24/04/2005  32.608  31.223   29.690      NaN  25.056  23.082  27.061   \n",
      "5365   23/04/2005  34.678  33.476   33.022      NaN  32.158  32.677  33.107   \n",
      "5366   22/04/2005  33.171  32.054   30.861      NaN  29.630  29.509  31.058   \n",
      "\n",
      "      Hour 7  Hour 8  ...   Night  Off-Peak 1  Business  Offpeak  Morning  \\\n",
      "5362  33.251  45.393  ...  30.567      32.756    53.135      NaN      NaN   \n",
      "5363  30.958  37.292  ...  26.424      28.349    55.164      NaN      NaN   \n",
      "5364  14.199  20.016  ...  28.120      25.367    30.583      NaN      NaN   \n",
      "5365  32.184  35.465  ...  33.186      33.346    43.878      NaN      NaN   \n",
      "5366  36.065  48.054  ...  31.047      33.800    56.422      NaN      NaN   \n",
      "\n",
      "      High Noon  Afternoon  Evening  Sunpeak  Sun Peak  \n",
      "5362        NaN        NaN      NaN      NaN       NaN  \n",
      "5363        NaN        NaN      NaN      NaN       NaN  \n",
      "5364        NaN        NaN      NaN      NaN       NaN  \n",
      "5365        NaN        NaN      NaN      NaN       NaN  \n",
      "5366        NaN        NaN      NaN      NaN       NaN  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Le fichier auction_spot_prices_france_2019.csv comprend tous les prix de 2005 à 2019\n",
    "# On va donc se baser dessus pour récupérer la majorité des données et y ajouter ensuite les données de 2020 à 2024\n",
    "spot_2005_2019 = pd.read_csv(os.path.join(data, \"auction_spot_prices_france_2019.csv\"), header=1, sep=',')\n",
    "print(f\"Table spot_2005_2019 créée - Shape: {spot_2005_2019.shape}\")\n",
    "print(spot_2005_2019.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6fc95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Delivery day  Hour 1  Hour 2  Hour 3  Hour 4  Hour 5  Hour 6  Hour 7  \\\n",
      "5362   26/04/2005  33.664  32.002  30.328  27.296  27.006  33.108  33.251   \n",
      "5363   25/04/2005  29.003  28.324  27.047  23.186  18.976  32.009  30.958   \n",
      "5364   24/04/2005  32.608  31.223  29.690  25.056  23.082  27.061  14.199   \n",
      "5365   23/04/2005  34.678  33.476  33.022  32.158  32.677  33.107  32.184   \n",
      "5366   22/04/2005  33.171  32.054  30.861  29.630  29.509  31.058  36.065   \n",
      "\n",
      "      Hour 8  Hour 9  ...  Hour 15  Hour 16  Hour 17  Hour 18  Hour 19  \\\n",
      "5362  45.393  52.304  ...   51.294   49.551   45.913   44.208   44.009   \n",
      "5363  37.292  49.496  ...   55.070   50.693   50.085   46.469   45.085   \n",
      "5364  20.016  29.801  ...   27.587   28.079   29.816   32.025   33.000   \n",
      "5365  35.465  41.893  ...   41.282   36.000   34.092   34.389   34.912   \n",
      "5366  48.054  55.994  ...   51.359   48.471   44.529   43.187   43.009   \n",
      "\n",
      "      Hour 20  Hour 21  Hour 22  Hour 23  Hour 24  \n",
      "5362   43.523   45.109   44.675   41.410   35.292  \n",
      "5363   43.999   36.528   37.646   33.176   34.353  \n",
      "5364   33.163   33.120   32.021   33.250   30.928  \n",
      "5365   35.050   43.020   42.623   40.093   34.096  \n",
      "5366   42.379   44.850   44.321   40.172   35.752  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# On supprime les colonnes dont on n'a pas besoin\n",
    "spot_2005_2019 = spot_2005_2019.iloc[:, 0:26]\n",
    "spot_2005_2019 = spot_2005_2019.drop(columns=['Hour 3B'])\n",
    "spot_2005_2019 = spot_2005_2019.rename(columns={'Hour 3A' : 'Hour 3'})\n",
    "print(spot_2005_2019.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f6f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Delivery day  Hour 1  Hour 2  Hour 3  Hour 4  Hour 5  Hour 6  Hour 7  \\\n",
      "0   2005-04-22  33.171  32.054  30.861  29.630  29.509  31.058  36.065   \n",
      "1   2005-04-23  34.678  33.476  33.022  32.158  32.677  33.107  32.184   \n",
      "2   2005-04-24  32.608  31.223  29.690  25.056  23.082  27.061  14.199   \n",
      "3   2005-04-25  29.003  28.324  27.047  23.186  18.976  32.009  30.958   \n",
      "4   2005-04-26  33.664  32.002  30.328  27.296  27.006  33.108  33.251   \n",
      "\n",
      "   Hour 8  Hour 9  ...  Hour 15  Hour 16  Hour 17  Hour 18  Hour 19  Hour 20  \\\n",
      "0  48.054  55.994  ...   51.359   48.471   44.529   43.187   43.009   42.379   \n",
      "1  35.465  41.893  ...   41.282   36.000   34.092   34.389   34.912   35.050   \n",
      "2  20.016  29.801  ...   27.587   28.079   29.816   32.025   33.000   33.163   \n",
      "3  37.292  49.496  ...   55.070   50.693   50.085   46.469   45.085   43.999   \n",
      "4  45.393  52.304  ...   51.294   49.551   45.913   44.208   44.009   43.523   \n",
      "\n",
      "   Hour 21  Hour 22  Hour 23  Hour 24  \n",
      "0   44.850   44.321   40.172   35.752  \n",
      "1   43.020   42.623   40.093   34.096  \n",
      "2   33.120   32.021   33.250   30.928  \n",
      "3   36.528   37.646   33.176   34.353  \n",
      "4   45.109   44.675   41.410   35.292  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concaténer les données de 2020 à 2024\n",
    "spot_2005_2024 = pd.concat([spot_2005_2019, spot_2020, spot_2021, spot_2022, spot_2023, spot_2024], ignore_index=True)\n",
    "spot_2005_2024['Delivery day'] = pd.to_datetime(spot_2005_2024['Delivery day'], format='%d/%m/%Y')\n",
    "spot_2005_2024 = spot_2005_2024.sort_values(by='Delivery day').reset_index(drop=True)\n",
    "print(spot_2005_2024.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177a35ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  datetime   price\n",
      "172651 2024-12-31 19:00:00  111.22\n",
      "172652 2024-12-31 20:00:00   92.78\n",
      "172653 2024-12-31 21:00:00   79.04\n",
      "172654 2024-12-31 22:00:00   50.11\n",
      "172655 2024-12-31 23:00:00   63.36\n"
     ]
    }
   ],
   "source": [
    "# On doit mainteant rattaché l'heure à la date donc on doit démultiplier les lignes pour chaque heure de la même date\n",
    "# On a les heures en colonne B à Z - 2 à 26\n",
    "df = spot_2005_2024.copy()\n",
    "# Transformation des colonnes heures en lignes\n",
    "hour_columns = [col for col in df.columns if 'Hour' in str(col)]\n",
    "date_col = df.columns[0]\n",
    "\n",
    "# Melt des données\n",
    "spot_hourly = pd.melt(\n",
    "    df,\n",
    "    id_vars=[date_col],\n",
    "    value_vars=hour_columns,\n",
    "    var_name='hour_col',\n",
    "    value_name='price'\n",
    ")\n",
    "\n",
    "# Extraire le numéro d'heure et créer datetime\n",
    "spot_hourly['hour'] = spot_hourly['hour_col'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# Correctif de l'heure où 00:00:00 = Hour 24 pour que le df commence avec la bonne colonne (et non Hour 1 par défaut qui correspond à 01:00:00)\n",
    "def convert_hour_to_datetime(row):\n",
    "    date = pd.to_datetime(row[date_col])\n",
    "    hour = row['hour']\n",
    "    \n",
    "    if hour == 24:\n",
    "        # Hour 24 correspond à 00:00:00\n",
    "        return date\n",
    "    else:\n",
    "        # Hour 1 = 01:00:00, Hour 2 = 02:00:00, etc.\n",
    "        return date + pd.to_timedelta(hour, unit='h')\n",
    "\n",
    "spot_hourly['datetime'] = spot_hourly.apply(convert_hour_to_datetime, axis=1)\n",
    "\n",
    "# Dataset final\n",
    "spot_final = spot_hourly[['datetime', 'price']].sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(spot_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3c8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "spot_final.to_csv(os.path.join(Output, \"historique_spot_2005_2024.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2172a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime   price\n",
      "0 2005-04-22 00:00:00  35.752\n",
      "1 2005-04-22 01:00:00  33.171\n",
      "2 2005-04-22 02:00:00  32.054\n",
      "3 2005-04-22 03:00:00  30.861\n",
      "4 2005-04-22 04:00:00  29.630\n"
     ]
    }
   ],
   "source": [
    "# On va ajouter les prix 2025 au fichier\n",
    "spot_2025 = pd.read_csv(os.path.join(Output, \"prix_spot.csv\"), sep=\";\")\n",
    "spot_2025['date'] = pd.to_datetime(spot_2025['date'])\n",
    "spot_2025 = spot_2025.rename(columns={'date': 'datetime', 'Price': 'price'})\n",
    "spot_2025 = spot_2025[spot_2025['datetime'].dt.year == 2025]\n",
    "# print(spot_2025.head())\n",
    "# On va concaténer les données de 2025 avec celles de 2005 à 2024\n",
    "spot_2005_2025 = pd.concat([spot_final, spot_2025], ignore_index=True)\n",
    "spot_2005_2025 = spot_2005_2025.sort_values(by='datetime').reset_index(drop=True)\n",
    "print(spot_2005_2025.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c3a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde en csv\n",
    "spot_2005_2025.to_csv(os.path.join(Output, \"historique_spot_2005_2025.csv\"), index=False)\n",
    "\n",
    "# Attention, ce fichier ne comprend pas la date du 17/07/2025 complète (au 04/08/2025 11h03)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
