{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ce141e",
   "metadata": {},
   "source": [
    "## Prix Spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571bc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies nécessaires\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9945fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin d'accès\n",
    "donnees = r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\Soutirage\\forecast-perimetre-TR\\Output\"\n",
    "dossier = r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\P50\\Injection\\test-models\\Consommation\"\n",
    "output = r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\P50\\Injection\\test-models\\Consommation\\Output\"\n",
    "\n",
    "# Meryam GHASSIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac32762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les données de Prix Spot depuis BigQuery (€/MWh)\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\P50\\Injection\\test-models\\Consommation\\credentials.json\"\n",
    "\n",
    "def get_bigquery_client(table_id):\n",
    "    client = bigquery.Client()\n",
    "    table = client.get_table(table_id)\n",
    "    df = client.list_rows(table).to_dataframe()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d58745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meryam GHASSIR\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\cloud\\bigquery\\table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Price\n",
      "date                       \n",
      "2025-09-09 19:00:00   90.00\n",
      "2025-09-09 20:00:00  111.37\n",
      "2025-09-09 21:00:00   91.60\n",
      "2025-09-09 22:00:00   95.49\n",
      "2025-09-09 23:00:00   78.37\n"
     ]
    }
   ],
   "source": [
    "table_spot = \"gcp-data-energy-11459.RTE_Data.spot-prices\"\n",
    "df_spot = get_bigquery_client(table_spot)\n",
    "\n",
    "# Ordonner les données par ordre croissant chronologique\n",
    "df_spot['Timestamp'] = pd.to_datetime(df_spot['Timestamp'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "df_spot = df_spot.sort_values(by='Timestamp', ascending=True)\n",
    "df_spot.rename(columns={'Timestamp' : 'date'}, inplace=True)\n",
    "df_spot.set_index('date', inplace=True)\n",
    "\n",
    "paris_tz = pytz.timezone(\"Europe/Paris\")\n",
    "df_spot.index = df_spot.index.tz_convert(paris_tz)\n",
    "\n",
    "df_spot.index = pd.to_datetime(df_spot.index).tz_localize(None)\n",
    "\n",
    "print(df_spot.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fef4f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb dates manquantes dans df_spot : 332\n",
      "Dates manquantes : DatetimeIndex(['2008-03-30 02:00:00', '2009-03-29 02:00:00',\n",
      "               '2010-03-28 02:00:00', '2011-03-27 02:00:00',\n",
      "               '2012-03-25 02:00:00', '2013-03-31 02:00:00',\n",
      "               '2014-03-30 02:00:00', '2015-03-29 02:00:00',\n",
      "               '2016-03-27 02:00:00', '2017-03-26 02:00:00',\n",
      "               ...\n",
      "               '2025-09-05 14:00:00', '2025-09-05 15:00:00',\n",
      "               '2025-09-05 16:00:00', '2025-09-05 17:00:00',\n",
      "               '2025-09-05 18:00:00', '2025-09-05 19:00:00',\n",
      "               '2025-09-05 20:00:00', '2025-09-05 21:00:00',\n",
      "               '2025-09-05 22:00:00', '2025-09-05 23:00:00'],\n",
      "              dtype='datetime64[ns]', length=332, freq=None)\n",
      "         Missing Date\n",
      "0 2008-03-30 02:00:00\n",
      "1 2009-03-29 02:00:00\n",
      "2 2010-03-28 02:00:00\n",
      "3 2011-03-27 02:00:00\n",
      "4 2012-03-25 02:00:00\n"
     ]
    }
   ],
   "source": [
    "# Vérification de valeurs manquantes dans df_spot\n",
    "\n",
    "date_range = pd.date_range(start=df_spot.index.min(), end=df_spot.index.max(), freq='h')\n",
    "missing_dates = date_range.difference(df_spot.index)\n",
    "print(f\"Nb dates manquantes dans df_spot : {len(missing_dates)}\")\n",
    "if len(missing_dates) > 0:\n",
    "    print(\"Dates manquantes :\", missing_dates)\n",
    "\n",
    "df_missing_dates = pd.DataFrame({'Missing Date': missing_dates})\n",
    "df_missing_dates['Missing Date'] = df_missing_dates['Missing Date'].dt.tz_localize(None)\n",
    "\n",
    "print(df_missing_dates.head())\n",
    "df_missing_dates.to_csv(\"dates_manquantes_spot.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b388fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Price\n",
      "date                      \n",
      "2008-01-01 01:00:00  71.19\n",
      "2008-01-01 02:00:00  68.94\n",
      "2008-01-01 03:00:00  62.92\n",
      "2008-01-01 04:00:00  47.98\n",
      "2008-01-01 05:00:00  44.99\n"
     ]
    }
   ],
   "source": [
    "# df_spot.rename(columns={'Timestamp':'date'}, inplace=True)\n",
    "# df_spot['date'] = pd.to_datetime(df_spot['date'])        \n",
    "df_spot.index = df_spot.index.tz_localize(None)   \n",
    "# df_spot.set_index('date', inplace=True)\n",
    "df_spot.sort_values(by='date', inplace=True)\n",
    "print(df_spot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a54e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauverage du DataFrame df_spot dans un fichier CSV (si pas de données manquantes)\n",
    "df_spot.to_csv(\"prix_spot.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2878d",
   "metadata": {},
   "source": [
    "**On s'arrête à cette étape du code s'il n'y a pas de de données manquantes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d4214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Price\n",
      "date                       \n",
      "2025-09-09 19:00:00   90.00\n",
      "2025-09-09 20:00:00  111.37\n",
      "2025-09-09 21:00:00   91.60\n",
      "2025-09-09 22:00:00   95.49\n",
      "2025-09-09 23:00:00   78.37\n"
     ]
    }
   ],
   "source": [
    "# Créer les dates manquantes dans df_spot en important le fichier des dates manquantes\n",
    "df_missing_dates = pd.read_csv(\"dates_manquantes_spot.csv\", sep=\";\")\n",
    "df_missing_dates['Missing Date'] = pd.to_datetime(df_missing_dates['Missing Date'])\n",
    "\n",
    "# Harmoniser l'index de df_spot (retirer la timezone si présente)\n",
    "df_spot.index = pd.to_datetime(df_spot.index)\n",
    "if hasattr(df_spot.index, 'tz'):\n",
    "    df_spot.index = df_spot.index.tz_localize(None)\n",
    "\n",
    "# Ajout des lignes pour les dates manquantes dans df_spot avec valeurs NaN\n",
    "for missing_date in df_missing_dates['Missing Date']:\n",
    "    if missing_date not in df_spot.index:\n",
    "        df_spot.loc[missing_date] = None  # Ajouter une ligne avec la date manquante et des valeurs NaN\n",
    "\n",
    "df_spot.sort_index(inplace=True)\n",
    "print(df_spot.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0957fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb dates manquantes dans df_spot : 0\n",
      "Empty DataFrame\n",
      "Columns: [Missing Date]\n",
      "Index: []\n",
      "Nombre de valeurs NaN dans df_spot : 332\n"
     ]
    }
   ],
   "source": [
    "# Vérification des dates manquantes dans df_spot après ajout\n",
    "\n",
    "date_range = pd.date_range(start=df_spot.index.min(), end=df_spot.index.max(), freq='h')\n",
    "missing_dates = date_range.difference(df_spot.index)\n",
    "print(f\"Nb dates manquantes dans df_spot : {len(missing_dates)}\")\n",
    "if len(missing_dates) > 0:\n",
    "    print(\"Dates manquantes :\", missing_dates)\n",
    "\n",
    "df_missing_dates = pd.DataFrame({'Missing Date': missing_dates})\n",
    "print(df_missing_dates.head())\n",
    "df_missing_dates.to_csv(\"dates_manquantes_spot.csv\", index=False, sep=\";\")\n",
    "\n",
    "# Nombre de valeurs NaN dans df_spot\n",
    "# On doit avoir le même nombre de valeurs NaN que de dates manquantes\n",
    "nan_count = df_spot.isna().sum().sum()\n",
    "print(f\"Nombre de valeurs NaN dans df_spot : {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4943c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  Prix Spot\n",
      "154532  2025-08-22 19:00:00      84.56\n",
      "154533  2025-08-22 20:00:00     104.53\n",
      "154534  2025-08-22 21:00:00     103.49\n",
      "154535  2025-08-22 22:00:00     101.59\n",
      "154536  2025-08-22 23:00:00      94.37\n",
      "                      Price\n",
      "date                       \n",
      "2025-08-22 19:00:00   84.56\n",
      "2025-08-22 20:00:00  104.53\n",
      "2025-08-22 21:00:00  103.49\n",
      "2025-08-22 22:00:00  101.59\n",
      "2025-08-22 23:00:00   94.37\n"
     ]
    }
   ],
   "source": [
    "# On récupère les données de prix spot depuis le fichier EPEX FR \n",
    "df_epex = pd.read_csv(r\"C:\\Users\\Meryam GHASSIR\\UPLE Dropbox\\Achat & Appro\\SAUVEGARDE OUTILS\\Calcul-Portefeuille\\HPFC\\EPEX_FR.csv\", sep=\";\") #, parse_dates=['date'], index_col='date')\n",
    "print(df_epex.tail())\n",
    "\n",
    "# Harmoniser la colonne date qui est au format 'dd/mm/yyyy hh:mm' et la convertir en format datetime 'yyyy-mm-dd hh:mm:ss'\n",
    "df_epex['date'] = pd.to_datetime(df_epex['date']) # df_epex['date'] = pd.to_datetime(df_epex['date'], format='%d/%m/%Y %H:%M.') # IGNORE\n",
    "df_epex.set_index('date', inplace=True)\n",
    "\n",
    "df_epex.rename(columns={'Prix Spot': 'Price'}, inplace=True)\n",
    "df_epex.sort_values(by='date', inplace=True)\n",
    "\n",
    "print(df_epex.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75fd421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb dates manquantes dans df_epex : 123\n",
      "Dates manquantes dans df_epex : DatetimeIndex(['2022-03-27 02:00:00', '2024-03-31 02:00:00',\n",
      "               '2025-03-30 02:00:00', '2025-08-05 00:00:00',\n",
      "               '2025-08-05 01:00:00', '2025-08-05 02:00:00',\n",
      "               '2025-08-05 03:00:00', '2025-08-05 04:00:00',\n",
      "               '2025-08-05 05:00:00', '2025-08-05 06:00:00',\n",
      "               ...\n",
      "               '2025-08-17 14:00:00', '2025-08-17 15:00:00',\n",
      "               '2025-08-17 16:00:00', '2025-08-17 17:00:00',\n",
      "               '2025-08-17 18:00:00', '2025-08-17 19:00:00',\n",
      "               '2025-08-17 20:00:00', '2025-08-17 21:00:00',\n",
      "               '2025-08-17 22:00:00', '2025-08-17 23:00:00'],\n",
      "              dtype='datetime64[ns]', length=123, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Dates manquantes dans df_epex (contrôle dates manquantes dans le fichier EPEX FR pour voir si on peut effectivement utiliser \n",
    "# ce fichier pour remplacer les NaN dans df_spot)\n",
    "date_range_epex = pd.date_range(start=df_epex.index.min(), end=df_epex.index.max(), freq='h')\n",
    "missing_dates_epex = date_range_epex.difference(df_epex.index)\n",
    "print(f\"Nb dates manquantes dans df_epex : {len(missing_dates_epex)}\")\n",
    "if len(missing_dates_epex) > 0:\n",
    "    print(\"Dates manquantes dans df_epex :\", missing_dates_epex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcae6910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Price\n",
      "date                      \n",
      "2022-03-27 02:00:00    NaN\n",
      "2024-03-31 02:00:00    NaN\n",
      "2025-03-30 02:00:00    NaN\n",
      "2025-08-05 00:00:00    NaN\n",
      "2025-08-05 01:00:00    NaN\n",
      "...                    ...\n",
      "2025-08-17 19:00:00    NaN\n",
      "2025-08-17 20:00:00    NaN\n",
      "2025-08-17 21:00:00    NaN\n",
      "2025-08-17 22:00:00    NaN\n",
      "2025-08-17 23:00:00    NaN\n",
      "\n",
      "[123 rows x 1 columns]\n",
      "Nombre de valeurs NaN dans df_spot après remplacement : 123\n"
     ]
    }
   ],
   "source": [
    "# On remplace les valeurs NaN de df_spot par les valeurs correspondantes de df_epex\n",
    "\n",
    "# Supprimer les doublons d'index en gardant la première occurrence\n",
    "df_spot = df_spot[~df_spot.index.duplicated(keep='first')]\n",
    "df_epex = df_epex[~df_epex.index.duplicated(keep='first')]\n",
    "\n",
    "# Remplacer les valeurs NaN dans df_spot par les valeurs correspondantes de df_epex\n",
    "df_spot['Price'] = df_spot['Price'].combine_first(df_epex['Price'])\n",
    "\n",
    "nan_spot = df_spot[df_spot['Price'].isna()]\n",
    "\n",
    "# Vérifier le résultat\n",
    "print(df_spot[df_spot['Price'].isna()])  # Affiche les lignes où il reste des NaN\n",
    "print(f\"Nombre de valeurs NaN dans df_spot après remplacement : {df_spot['Price'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d53f543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Price\n",
      "date                      \n",
      "2025-08-05 00:00:00    NaN\n",
      "2025-08-05 01:00:00    NaN\n",
      "2025-08-05 02:00:00    NaN\n",
      "2025-08-05 03:00:00    NaN\n",
      "2025-08-05 04:00:00    NaN\n",
      "...                    ...\n",
      "2025-08-17 19:00:00    NaN\n",
      "2025-08-17 20:00:00    NaN\n",
      "2025-08-17 21:00:00    NaN\n",
      "2025-08-17 22:00:00    NaN\n",
      "2025-08-17 23:00:00    NaN\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "Nombre de valeurs NaN dans df_spot après remplacement : 120\n"
     ]
    }
   ],
   "source": [
    "# Ajout des dates manquantes de 2022-03-27 02:00:00 et 2024-03-31 02:00:00 (passage à l'heure d'été, conso = 0MWh)\n",
    "\n",
    "# Mettre à 0 les valeurs manquantes du 2022-03-27 02:00:00 et du 2024-03-31 02:00:00\n",
    "df_spot.loc[df_spot.index == pd.Timestamp('2022-03-27 02:00:00'), 'Price'] = 0.0\n",
    "df_spot.loc[df_spot.index == pd.Timestamp('2024-03-31 02:00:00'), 'Price'] = 0.0\n",
    "df_spot.loc[df_spot.index == pd.Timestamp('2025-03-30 02:00:00'), 'Price'] = 0.0\n",
    "\n",
    "print(df_spot[df_spot['Price'].isna()]) \n",
    "print(f\"Nombre de valeurs NaN dans df_spot après remplacement : {df_spot['Price'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6186e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Price]\n",
      "Index: []\n",
      "Nombre de valeurs NaN dans df_spot après remplacement : 0\n"
     ]
    }
   ],
   "source": [
    "# Retraitement exceptionnel : Suppression de toutes les dates à partir du 5 août (absence du 5, 6, 7, 10 et 17 août 2025)\n",
    "df_spot = df_spot[df_spot.index < '2025-08-05']\n",
    "print(df_spot[df_spot['Price'].isna()]) \n",
    "print(f\"Nombre de valeurs NaN dans df_spot après remplacement : {df_spot['Price'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afc3929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Price]\n",
      "Index: []\n",
      "Nombre de valeurs NaN dans df_spot après remplacement : 0\n"
     ]
    }
   ],
   "source": [
    "# Retraitement exceptionnel pour les heures manquantes du 17 juillet 2025 (en attendant la régularisation - update : 04/08/2025 10h55)\n",
    "# Suppression des lignes NaN du 17 juillet 2025\n",
    "df_spot = df_spot[~df_spot.index.isin(pd.date_range(start='2025-07-17 00:00:00', end='2025-07-17 21:00:00', freq='h'))]\n",
    "\n",
    "print(df_spot[df_spot['Price'].isna()])\n",
    "print(f\"Nombre de valeurs NaN dans df_spot après remplacement : {df_spot['Price'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17f2dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le DataFrame df_spot dans un fichier CSV\n",
    "df_spot.to_csv(os.path.join(output, \"prix_spot.csv\"), index=True, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
